{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b3b37-3b29-4833-94f2-bfe47af00c83",
   "metadata": {},
   "source": [
    "# Lesson 6: Essay Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 63
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "    error_code: int\n",
    "    sop_content: str\n",
    "    available_tools: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_json_from_response(self, response_content: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extracts JSON from the LLM response.\"\"\"\n",
    "        json_pattern = r'```json\\s*(.*?)\\s*```'\n",
    "        json_match = re.search(json_pattern, response_content, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            json_str = json_match.group(1)\n",
    "        else:\n",
    "            json_str = response_content.strip()\n",
    "        \n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            json_start = response_content.find('{')\n",
    "            json_end = response_content.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_content[json_start:json_end]\n",
    "                return json.loads(json_str)\n",
    "            else:\n",
    "                raise ValueError(f\"Could not extract valid JSON from response: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "def planner(llm,state: AgentState) -> AgentState:\n",
    "    error_code = state[\"error_code\"]\n",
    "    sop_content = state[\"sop_content\"]\n",
    "    available_tools = state[\"available_tools\"]\n",
    "    tool_descriptions = []\n",
    "    for tool in available_tools:\n",
    "        tool_descriptions.append(f\"- {tool.name}: {tool.description}\")\n",
    "    \n",
    "    planner_prompt = f\"\"\"\n",
    "        You are an expert SOP analyzer that creates ReAct-optimized playbooks for intelligent execution agents.\n",
    "        \n",
    "        Your task is to analyze the SOP and create a JSON playbook where each step provides enough context \n",
    "        for a ReAct agent to intelligently choose tools and make decisions based on tool outcomes.\n",
    "        \n",
    "        AVAILABLE TOOLS:\n",
    "        {chr(10).join(tool_descriptions)}\n",
    "        \n",
    "        CRITICAL DESIGN PRINCIPLES:\n",
    "        1. Each step should define OBJECTIVES, not specific tools to use\n",
    "        2. Include clear SUCCESS and FAILURE criteria that a ReAct agent can evaluate\n",
    "        3. Steps should be tool-agnostic - let the ReAct agent choose the best tool for the objective\n",
    "        4. Provide rich context about what each step is trying to achieve\n",
    "        5. Design conditional flows that can handle multiple scenarios\n",
    "        \n",
    "        Guidelines for ReAct-optimized playbooks:\n",
    "        1. Focus on WHAT needs to be achieved, not HOW to achieve it\n",
    "        2. Provide clear success/failure criteria for each step\n",
    "        3. Include context requirements (what data/information is needed)\n",
    "        4. Design steps that allow the ReAct agent to reason about tool selection\n",
    "        5. Create robust error handling and alternative paths\n",
    "        6. Each step should be self-contained with clear objectives\n",
    "        \n",
    "        Error Code Context: {error_code}\n",
    "        \n",
    "        IMPORTANT: Return ONLY the JSON playbook, no other text or explanations.\n",
    "        \"\"\"\n",
    "        \n",
    "    human_prompt = f\"\"\"\n",
    "        Create a ReAct-optimized JSON playbook for this SOP:\n",
    "        \n",
    "        {sop_content}\n",
    "        \n",
    "        Required JSON structure:\n",
    "        {{\n",
    "            \"name\": \"Playbook name\",\n",
    "            \"description\": \"What this playbook accomplishes\",\n",
    "            \"start_step\": \"first_step_id\",\n",
    "            \"steps\": {{\n",
    "                \"step_id\": {{\n",
    "                    \"id\": \"step_id\",\n",
    "                    \"name\": \"Step name\",\n",
    "                    \"action\": \"achieve_objective|evaluate_condition|notify|end\",\n",
    "                    \"objective\": \"What this step needs to accomplish\",\n",
    "                    \"success_criteria\": \"How to determine success\",\n",
    "                    \"failure_criteria\": \"How to determine failure\", \n",
    "                    \"next_steps\": {{\"success\": \"next_id\", \"failure\": \"error_id\", \"default\": \"END\"}},\n",
    "                    \"description\": \"Detailed description\",\n",
    "                    \"context_requirements\": [\"required_data1\", \"required_data2\"]\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        RULES:\n",
    "        1. Use \"END\" for terminal steps\n",
    "        2. Focus on objectives, not specific tools\n",
    "        3. Include rich success/failure criteria\n",
    "        4. All referenced step IDs must exist\n",
    "        5. Make it ReAct agent friendly - provide reasoning context\n",
    "        \"\"\"\n",
    "        \n",
    "    messages = [\n",
    "            SystemMessage(content=planner_prompt),\n",
    "            HumanMessage(content=human_prompt)\n",
    "        ]\n",
    "    response = llm.invoke(messages)\n",
    "    playbook_json = _extract_json_from_response(response.content)\n",
    "    state[\"plan\"] = eval(playbook_json)\n",
    "    state[\"sop_content\"] = None\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2685401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "def call_llm(llm,tools,state: AgentState) -> AgentState:\n",
    "    \"\"\"Function to call the LLM with the current state.\"\"\"\n",
    "    llm = llm.bind_tools(tools)\n",
    "\n",
    "    react_template = f\"\"\"You are an intelligent workflow execution agent. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Your role is to execute workflow steps by:\n",
    "1. Understanding the objective of each step\n",
    "2. Choosing the most appropriate tool(s) to achieve the objective\n",
    "3. Evaluating tool results against success/failure criteria\n",
    "4. Making decisions about next steps based on outcomes\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the workflow step you need to execute\n",
    "Thought: analyze the objective and determine what needs to be done\n",
    "Action: choose the most appropriate action from [{tools}]\n",
    "Action Input: provide the necessary input for the action\n",
    "Observation: analyze the result of the action\n",
    "... (repeat Thought/Action/Action Input/Observation as needed)\n",
    "Thought: evaluate if the step objective has been achieved based on success/failure criteria\n",
    "Final Answer: provide a clear assessment of whether the step succeeded or failed, with reasoning\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. If no suitable tool exists for an objective, respond with \"NO_SUITABLE_TOOL\"\n",
    "2. If a tool fails or returns unsatisfactory results, try alternative approaches if available\n",
    "3. Always evaluate results against the provided success/failure criteria\n",
    "4. If you cannot achieve the objective after trying available tools, respond with \"OBJECTIVE_FAILED\"\n",
    "\n",
    "Begin! \"\"\"\n",
    "    response = llm.invoke().content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "def take_action(state: AgentState) -> AgentState:\n",
    "    \"\"\"Execute tool calls from the LLM's response.\"\"\"\n",
    "\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    results = []\n",
    "    for t in tool_calls:\n",
    "        print(f\"Calling Tool: {t['name']} with query: {t['args'].get('query', 'No query provided')}\")\n",
    "        \n",
    "        if not t['name'] in tools_dict: # Checks if a valid tool is present\n",
    "            print(f\"\\nTool: {t['name']} does not exist.\")\n",
    "            result = \"Incorrect Tool Name, Please Retry and Select tool from List of Available tools.\"\n",
    "        \n",
    "        else:\n",
    "            result = tools_dict[t['name']].invoke(t['args'].get('query', ''))\n",
    "            print(f\"Result length: {len(str(result))}\")\n",
    "            \n",
    "\n",
    "        # Appends the Tool Message\n",
    "        results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "\n",
    "    print(\"Tools Execution Complete. Back to the model!\")\n",
    "    return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"planner\", planner)\n",
    "graph.add_node(\"llm\", call_llm)\n",
    "graph.add_node(\"tools\", take_action)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    should_continue,\n",
    "    {True: \"tools\", False: END}\n",
    ")\n",
    "graph.add_edge(\"planner\", \"llm\")\n",
    "graph.add_edge(\"retriever_agent\", \"llm\")\n",
    "graph.set_entry_point(\"planner\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "agent = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871f644-b131-4065-b7ce-b82c20a41f11",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(agent.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in agent.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8a6cc-65d4-4ce7-87aa-4e67d7c23d7b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1664b5-75e0-46b7-9c2b-4ac9171f4597",
   "metadata": {},
   "source": [
    "## Essay Writer Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ae270-3ec3-484a-b729-df7d2b7b0f76",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper import ewriter, writer_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebfa79-c7fc-4aaa-b668-64e5b6cede80",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "MultiAgent = ewriter()\n",
    "app = writer_gui(MultiAgent.agent)\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b5e62-a203-433c-92a0-3783f490cde1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa923c-7e4f-42d1-965f-0f8ccd50fbd7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c6245-2837-4ac5-983b-95f61f3ac10d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910915-b087-4d35-afff-0ec30a5852f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb6cc-5129-4a99-bb45-851bc07b5709",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a02b4-96cc-4b01-8792-397a774eb499",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b86a6-5e20-4252-b1d8-009b8318345a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af925917-b746-48c9-ac74-62fefbe5246c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5048f2c-4d82-49a5-9cb1-918d78b39f7b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f7f1f-68b4-4462-bfa5-b6472ef1304a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac0aa9-baa7-4b58-889d-2118cc00c6b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6098b9-e2a9-4767-8cb5-346db835c8d2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23cf2a-a179-44dc-9ae3-2eddda4b67b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6005b-0221-4f5e-9be0-0580c1d03126",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1ec12-f1c8-41ae-bb3e-5f28997b9b99",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c07d7-be17-4c17-82c5-6fe1db028b8b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04592c8e-1cfe-4b26-93b5-caf1ed1e7d24",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181c4a9-0e71-4f67-b71f-18a225e37202",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c478a9-7bfe-49e2-8a7d-1536271f45a6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d6771-3fad-4f37-9b32-45b36ad85c59",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3629eb3-655d-467a-b413-63f547c2de08",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772f251-2b61-4d10-97c5-61cef9207a76",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de92979-7ac5-4a7c-91c1-10806b7d529c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c4325-f625-4bbf-9d74-cc58f10763f2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4070be7-72da-42f9-a25d-8a6c628788b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289efbe-7033-4f32-8482-2039c5f9db90",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e480bb-22ab-4acb-a42c-71da3d04a5b1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea35c-7483-4b3d-b5e3-76eb3a0fe536",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac5730-a9d5-4ea4-8546-ebcb265cf1da",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f28b-46d8-4bcd-b2e4-730376ee7ccf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac7020-b4f4-4bd2-a875-ccee93f83d83",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f79eb9-d1c9-44b0-9efd-a8f9b380332a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509206-bde1-43e4-a88f-8a565539d357",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba1590-9e7b-4c0f-9492-81a07d286c55",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fe4a8-5372-479d-b248-af7a295c86c1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514720a-14bc-4552-ade5-fa03f86f4c73",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
