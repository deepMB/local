from typing import TypedDict, List, Optional, Any, Dict, Literal
from langgraph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import BaseTool
from langchain_openai import ChatOpenAI
from langchain.agents import create_react_agent, AgentExecutor
from langchain_core.prompts import PromptTemplate
import json
import re
from pydantic import BaseModel, Field

# Agent State Definition
class AgentState(TypedDict):
    """
    Defines the shared state for the playbook-driven multi-agent system.
    """
    error_code: int
    sop_content: str
    
    playbook: Optional[Dict[str, Any]]
    """The structured JSON workflow graph generated by the Planning Agent."""

    execution_queue: List[str]
    """A queue of node IDs from the playbook that the Execution Agent needs to process."""
    
    data: Optional[Any]
    """Holds operational data, like the pandas DataFrame for error 935."""

    last_tool_result: Optional[Dict[str, Any]]
    """Stores the output from the last executed tool for conditional evaluation."""

    final_output: Dict[str, Any]
    """A dictionary to accumulate final results and statuses from the workflow."""

    current_step_id: Optional[str]
    """Currently executing step ID."""

    execution_status: str
    """Status of execution: 'planning', 'executing', 'completed', 'failed'."""

    execution_log: List[Dict[str, Any]]
    """Log of all executed steps and their results."""


# Playbook Schema for structured output
class PlaybookStep(BaseModel):
    """Represents a single step in the playbook"""
    id: str = Field(description="Unique identifier for the step")
    name: str = Field(description="Human-readable name of the step")
    action: str = Field(description="The action to be performed")
    tool_name: Optional[str] = Field(description="Name of the tool to use, if applicable")
    tool_args: Optional[Dict[str, Any]] = Field(description="Arguments for the tool")
    condition: Optional[str] = Field(description="Condition to evaluate for branching")
    next_steps: Dict[str, str] = Field(description="Next steps based on conditions (success, failure, etc.)")
    description: str = Field(description="Detailed description of what this step does")


class PlanningAgent:
    """
    Planning Agent that reads SOPs and creates structured JSON playbooks.
    """
    
    def __init__(self, llm: ChatOpenAI, available_tools: List[BaseTool]):
        self.llm = llm
        self.available_tools = available_tools
        self.tool_names = [tool.name for tool in available_tools]
        
    def analyze_sop(self, state: AgentState) -> AgentState:
        """
        Analyzes the SOP content and creates a structured playbook.
        """
        print("üîç Planning Agent: Starting SOP analysis...")
        
        sop_content = state["sop_content"]
        error_code = state["error_code"]
        
        # Update execution status
        state["execution_status"] = "planning"
        
        # Create detailed tool descriptions
        tool_descriptions = []
        for tool in self.available_tools:
            tool_descriptions.append(f"- {tool.name}: {tool.description}")
        
        # Create the system prompt for SOP analysis
        system_prompt = f"""
        You are an expert SOP (Standard Operating Procedure) analyzer and workflow designer.
        
        Your task is to analyze the given SOP content and create a structured JSON playbook that can be executed by an automation agent.
        
        AVAILABLE TOOLS (YOU MUST ONLY USE THESE TOOLS):
        {chr(10).join(tool_descriptions)}
        
        CRITICAL RULES:
        1. You can ONLY use tools from the available tools list above
        2. Do NOT create, invent, or reference any tools not in the list
        3. If a step requires a tool that's not available, use "action": "notify" instead
        4. Map each SOP step to the most appropriate available tool
        5. If no suitable tool exists for a step, make it a notification step
        
        Guidelines for creating the playbook:
        1. Break down the SOP into discrete, actionable steps
        2. Identify decision points and conditional logic (IF/ELSE scenarios)
        3. Map each step to appropriate tools where applicable (ONLY from available tools)
        4. Create a flow that handles both success and failure paths
        5. Ensure each step has clear next steps based on outcomes
        6. Use meaningful IDs for steps (e.g., "step_001_validate_data", "step_002_check_connection")
        
        For conditional steps:
        - Use "condition" field to specify what to evaluate
        - Use "next_steps" to define paths: {{"success": "next_step_id", "failure": "error_step_id", "default": "default_step_id"}}
        
        The playbook should be comprehensive enough that an execution agent can follow it step-by-step without ambiguity.
        
        Error Code Context: {error_code}
        
        IMPORTANT: Return ONLY the JSON playbook, no other text or explanations.
        """
        
        human_prompt = f"""
        Create a detailed JSON playbook for this SOP:
        
        {sop_content}
        
        Required JSON structure:
        {{
            "name": "Playbook name",
            "description": "What this playbook does",
            "start_step": "first_step_id",
            "steps": {{
                "step_id": {{
                    "id": "step_id",
                    "name": "Step name",
                    "action": "execute_tool|evaluate_condition|notify|end",
                    "tool_name": "tool_name_if_applicable",
                    "tool_args": {{"arg": "value"}},
                    "condition": "condition_to_evaluate_if_applicable",
                    "next_steps": {{"success": "next_id", "failure": "error_id", "default": "END"}},
                    "description": "What this step does"
                }}
            }}
        }}
        
        IMPORTANT RULES:
        1. Use "END" (uppercase) for terminal steps in next_steps
        2. Never use "end", "stop", "finish" - always use "END"
        3. Ensure all referenced step IDs actually exist in the steps dictionary
        4. Every step must have a valid next_steps path
        """
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        try:
            # Get structured output from LLM
            response = self.llm.invoke(messages)
            
            # Parse the response to extract JSON
            playbook_json = self._extract_json_from_response(response.content)
            
            # Validate and structure the playbook
            playbook = self._validate_and_structure_playbook(playbook_json)
            
            # Update state with the created playbook
            state["playbook"] = playbook
            state["execution_queue"] = [playbook["start_step"]] if playbook else []
            state["execution_status"] = "ready_to_execute"
            
            print(f"‚úÖ Planning Agent: Successfully created playbook with {len(playbook.get('steps', {}))} steps")
            print(f"üìã Start step: {playbook['start_step']}")
            
        except Exception as e:
            print(f"‚ùå Planning Agent Error: {str(e)}")
            state["playbook"] = None
            state["execution_queue"] = []
            state["execution_status"] = "failed"
            state["final_output"]["error"] = f"Planning failed: {str(e)}"
        
        return state
    
    def _extract_json_from_response(self, response_content: str) -> Dict[str, Any]:
        """Extracts JSON from the LLM response."""
        # Try to find JSON block in the response
        json_pattern = r'```json\s*(.*?)\s*```'
        json_match = re.search(json_pattern, response_content, re.DOTALL)
        
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON without code blocks
            json_str = response_content.strip()
        
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            # Fallback: try to extract JSON from anywhere in the text
            json_start = response_content.find('{')
            json_end = response_content.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = response_content[json_start:json_end]
                return json.loads(json_str)
            else:
                raise ValueError(f"Could not extract valid JSON from response: {str(e)}")
    
    def _validate_and_structure_playbook(self, playbook_json: Dict[str, Any]) -> Dict[str, Any]:
        """Validates the playbook structure and ensures only valid tools are used."""
        if "steps" not in playbook_json:
            raise ValueError("Playbook must contain 'steps' field")
        
        if "start_step" not in playbook_json:
            playbook_json["start_step"] = list(playbook_json["steps"].keys())[0]
        
        # Validate that start_step exists in steps
        if playbook_json["start_step"] not in playbook_json["steps"]:
            raise ValueError(f"Start step '{playbook_json['start_step']}' not found in steps")
        
        # Ensure each step has required fields and validate tool usage
        for step_id, step_data in playbook_json["steps"].items():
            if "id" not in step_data:
                step_data["id"] = step_id
            if "next_steps" not in step_data:
                step_data["next_steps"] = {"default": "END"}
            if "action" not in step_data:
                step_data["action"] = "execute_tool"
                
            # Validate tool usage - CRITICAL FIX
            if step_data.get("tool_name") and step_data["tool_name"] not in self.tool_names:
                print(f"‚ö†Ô∏è  Warning: Invalid tool '{step_data['tool_name']}' in step '{step_id}'. Converting to notification step.")
                step_data["action"] = "notify"
                step_data["description"] = f"Manual step required: {step_data.get('description', 'Execute manually')}"
                if "tool_name" in step_data:
                    del step_data["tool_name"]
                if "tool_args" in step_data:
                    del step_data["tool_args"]
                
            # Normalize any end step references to uppercase END
            if "next_steps" in step_data:
                normalized_next_steps = {}
                for condition, next_step in step_data["next_steps"].items():
                    if isinstance(next_step, str) and next_step.lower() in ['end', 'stop', 'finish', 'complete']:
                        normalized_next_steps[condition] = "END"
                    else:
                        normalized_next_steps[condition] = next_step
                step_data["next_steps"] = normalized_next_steps
        
        return playbook_json


class ExecutionAgent:
    """
    Execution Agent that executes the playbook using ReAct pattern with LLM.
    """
    
    def __init__(self, llm: ChatOpenAI, available_tools: List[BaseTool]):
        self.llm = llm
        self.available_tools = available_tools
        self.tool_dict = {tool.name: tool for tool in available_tools}
        
        # Create ReAct agent executor
        from langchain.agents import create_react_agent, AgentExecutor
        from langchain_core.prompts import PromptTemplate
        
        # ReAct prompt template
        react_template = """Answer the following questions as best you can. You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original question

Begin!

Question: {input}
Thought:{agent_scratchpad}"""

        self.react_prompt = PromptTemplate.from_template(react_template)
        
        # Create ReAct agent
        self.react_agent = create_react_agent(
            llm=self.llm,
            tools=self.available_tools,
            prompt=self.react_prompt
        )
        
        # Create agent executor
        self.agent_executor = AgentExecutor(
            agent=self.react_agent,
            tools=self.available_tools,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=5
        )
        
    def execute_step(self, state: AgentState) -> AgentState:
        """
        Executes the current step in the playbook.
        """
        if not state["execution_queue"]:
            state["execution_status"] = "completed"
            return state
            
        current_step_id = state["execution_queue"][0]
        state["current_step_id"] = current_step_id
        
        print(f"üîß Execution Agent: Executing step '{current_step_id}'")
        
        # Handle END step (case-insensitive)
        if current_step_id.upper() == "END":
            state["execution_status"] = "completed"
            state["execution_queue"] = []
            print("‚úÖ Execution Agent: Workflow completed successfully")
            return state
        
        # Get current step details
        if not state["playbook"] or current_step_id not in state["playbook"]["steps"]:
            # Check if it's a variation of END
            if current_step_id.lower() in ['end', 'stop', 'finish', 'complete']:
                state["execution_status"] = "completed"
                state["execution_queue"] = []
                print("‚úÖ Execution Agent: Workflow completed successfully")
                return state
            else:
                state["execution_status"] = "failed"
                state["final_output"]["error"] = f"Step '{current_step_id}' not found in playbook"
                return state
            
        current_step = state["playbook"]["steps"][current_step_id]
        
        try:
            # Execute the step based on its action type
            if current_step["action"] == "execute_tool":
                result = self._execute_tool_step(current_step, state)
            elif current_step["action"] == "evaluate_condition":
                result = self._evaluate_condition_step(current_step, state)
            elif current_step["action"] == "notify":
                result = self._notify_step(current_step, state)
            else:
                result = {"status": "success", "message": f"Executed step: {current_step['name']}"}
            
            # Log the execution
            log_entry = {
                "step_id": current_step_id,
                "step_name": current_step.get("name", ""),
                "result": result,
                "timestamp": "now"  # In real implementation, use actual timestamp
            }
            
            if "execution_log" not in state:
                state["execution_log"] = []
            state["execution_log"].append(log_entry)
            
            # Store last tool result
            state["last_tool_result"] = result
            
            # Determine next step
            next_step_id = self._determine_next_step(current_step, result)
            
            # Update execution queue
            state["execution_queue"] = state["execution_queue"][1:]  # Remove current step
            
            if next_step_id and next_step_id != "END":
                state["execution_queue"].insert(0, next_step_id)  # Add next step to front
            
            print(f"‚úÖ Step '{current_step_id}' completed. Next: '{next_step_id}'")
            
        except Exception as e:
            print(f"‚ùå Execution Agent Error in step '{current_step_id}': {str(e)}")
            state["execution_status"] = "failed"
            state["final_output"]["error"] = f"Execution failed at step '{current_step_id}': {str(e)}"
            
        return state
    
    def _execute_tool_step(self, step: Dict[str, Any], state: AgentState) -> Dict[str, Any]:
        """Execute a tool-based step using ReAct agent."""
        tool_name = step.get("tool_name")
        tool_args = step.get("tool_args", {})
        step_description = step.get("description", "")
        
        if not tool_name or tool_name not in self.tool_dict:
            return {"status": "failure", "message": f"Tool '{tool_name}' not available"}
        
        try:
            # Create detailed question for ReAct agent
            question = f"""
            Execute the following step from the playbook:
            
            Step: {step.get('name', 'Unnamed Step')}
            Description: {step_description}
            Tool to use: {tool_name}
            Tool arguments: {json.dumps(tool_args)}
            
            Context from previous steps:
            {json.dumps(state.get('last_tool_result', {}), indent=2)}
            
            Please execute this step and provide a clear result indicating success or failure.
            """
            
            print(f"ü§ñ Executing with LLM: {tool_name} with args {tool_args}")
            
            # Use ReAct agent to execute the step
            result = self.agent_executor.invoke({"input": question})
            
            # Extract the actual tool result if available
            tool_result = None
            if hasattr(result, 'get') and 'intermediate_steps' in result:
                for step_result in result['intermediate_steps']:
                    if len(step_result) > 1:
                        tool_result = step_result[1]  # Tool output
                        break
            
            # Determine if the step was successful based on the agent's output
            output = result.get('output', '') if hasattr(result, 'get') else str(result)
            
            # Simple success detection (can be enhanced)
            is_successful = any(keyword in output.lower() for keyword in ['success', 'completed', 'valid', 'connected', 'executed'])
            
            return {
                "status": "success" if is_successful else "failure",
                "tool_name": tool_name,
                "tool_args": tool_args,
                "tool_result": tool_result,
                "agent_output": output,
                "message": f"{'Successfully executed' if is_successful else 'Failed to execute'} {tool_name}"
            }
            
        except Exception as e:
            print(f"‚ùå Error executing step with ReAct agent: {str(e)}")
            return {
                "status": "failure",
                "tool_name": tool_name,
                "error": str(e),
                "message": f"Failed to execute {tool_name}: {str(e)}"
            }
    
    def _evaluate_condition_step(self, step: Dict[str, Any], state: AgentState) -> Dict[str, Any]:
        """Evaluate a conditional step using LLM reasoning."""
        condition = step.get("condition", "")
        last_result = state.get("last_tool_result", {})
        
        try:
            # Use LLM to evaluate the condition
            evaluation_question = f"""
            Evaluate the following condition based on the previous step result:
            
            Condition to evaluate: {condition}
            Previous step result: {json.dumps(last_result, indent=2)}
            
            Determine if the condition is met (True/False) and explain your reasoning.
            Respond with: CONDITION_MET: True/False followed by your explanation.
            """
            
            response = self.llm.invoke([HumanMessage(content=evaluation_question)])
            response_text = response.content.lower()
            
            # Parse the LLM response
            condition_met = "condition_met: true" in response_text or "true" in response_text.split('\n')[0]
            
            return {
                "status": "success" if condition_met else "failure",
                "condition": condition,
                "condition_met": condition_met,
                "llm_reasoning": response.content,
                "message": f"Condition '{condition}' evaluated to {condition_met}"
            }
            
        except Exception as e:
            # Fallback to simple condition evaluation
            if "success" in condition.lower():
                condition_met = last_result.get("status") == "success"
            elif "failure" in condition.lower():
                condition_met = last_result.get("status") == "failure"
            else:
                condition_met = bool(last_result.get("status") == "success")
            
            return {
                "status": "success" if condition_met else "failure",
                "condition": condition,
                "condition_met": condition_met,
                "error": str(e),
                "message": f"Condition '{condition}' evaluated to {condition_met} (fallback)"
            }
    
    def _notify_step(self, step: Dict[str, Any], state: AgentState) -> Dict[str, Any]:
        """Handle notification steps."""
        message = step.get("description", "Notification step executed")
        
        # In real implementation, this could send actual notifications
        print(f"üì¢ Notification: {message}")
        
        return {
            "status": "success",
            "message": f"Notification sent: {message}"
        }
    
    def _determine_next_step(self, current_step: Dict[str, Any], result: Dict[str, Any]) -> str:
        """Determine the next step based on the current step result."""
        next_steps = current_step.get("next_steps", {})
        result_status = result.get("status", "unknown")
        
        # Try to find next step based on result status
        next_step = None
        if result_status in next_steps:
            next_step = next_steps[result_status]
        elif "default" in next_steps:
            next_step = next_steps["default"]
        else:
            next_step = "END"
        
        # Normalize end step variations to uppercase END
        if next_step and next_step.lower() in ['end', 'stop', 'finish', 'complete']:
            next_step = "END"
            
        return next_step


def create_multi_agent_workflow(llm: ChatOpenAI, available_tools: List[BaseTool]) -> StateGraph:
    """
    Creates the multi-agent workflow with both Planning and Execution agents.
    """
    planning_agent = PlanningAgent(llm, available_tools)
    execution_agent = ExecutionAgent(llm, available_tools)
    
    # Create the state graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("planning", planning_agent.analyze_sop)
    workflow.add_node("execution", execution_agent.execute_step)
    
    # Set entry point
    workflow.set_entry_point("planning")
    
    # Define routing logic
    def route_after_planning(state: AgentState) -> Literal["execution", "__end__"]:
        """Route after planning phase."""
        if state["execution_status"] == "ready_to_execute" and state["execution_queue"]:
            return "execution"
        else:
            return "__end__"
    
    def route_after_execution(state: AgentState) -> Literal["execution", "__end__"]:
        """Route after execution phase."""
        if state["execution_status"] == "completed" or state["execution_status"] == "failed":
            return "__end__"
        elif state["execution_queue"]:
            return "execution"
        else:
            return "__end__"
    
    # Add conditional edges
    workflow.add_conditional_edges(
        "planning",
        route_after_planning,
        {
            "execution": "execution",
            "__end__": END
        }
    )
    
    workflow.add_conditional_edges(
        "execution",
        route_after_execution,
        {
            "execution": "execution",
            "__end__": END
        }
    )
    
    return workflow


# Example usage and testing
if __name__ == "__main__":
    from langchain_core.tools import tool
    
    # Mock tools for demonstration
    @tool
    def validate_data(data_source: str) -> str:
        """Validates data from the specified source."""
        return f"Data validation completed for {data_source} - Status: Valid"
    
    @tool
    def check_database_connection(database_name: str) -> str:
        """Checks connection to the specified database."""
        return f"Database connection verified for {database_name} - Status: Connected"
    
    @tool
    def execute_query(query: str) -> str:
        """Executes a database query."""
        return f"Query executed successfully: {query} - Rows affected: 150"
    
    @tool
    def send_notification(message: str, recipient: str) -> str:
        """Sends a notification message."""
        return f"Notification sent to {recipient}: {message} - Status: Delivered"
    
    # Initialize LLM (replace with your preferred LLM)
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    # Available tools
    tools = [validate_data, check_database_connection, execute_query, send_notification]
    
    # Create the multi-agent workflow
    workflow = create_multi_agent_workflow(llm, tools)
    
    # Compile the graph
    app = workflow.compile()
    
    # Example SOP content
    sample_sop = """
    SOP for Error Code 935 - Data Validation Failure
    
    1. First, validate the incoming data source 'customer_data'
    2. If validation fails, check database connection to 'main_db'
    3. If connection is successful, execute repair query 'UPDATE customers SET status = active WHERE status IS NULL'
    4. If repair is successful, re-validate the data source
    5. If re-validation passes, send success notification to 'admin@company.com'
    6. If any step fails, send error notification with details to 'admin@company.com'
    """
    
    # Test the multi-agent system
    initial_state: AgentState = {
        "error_code": 935,
        "sop_content": sample_sop,
        "playbook": None,
        "execution_queue": [],
        "data": None,
        "last_tool_result": None,
        "final_output": {},
        "current_step_id": None,
        "execution_status": "planning",
        "execution_log": []
    }
    
    # Run the multi-agent workflow
    try:
        print("üöÄ Starting Multi-Agent Workflow...")
        print("=" * 50)
        
        result = app.invoke(initial_state)
        
        print("=" * 50)
        print("üìä Final Results:")
        print(f"Execution Status: {result['execution_status']}")
        print(f"Steps Executed: {len(result.get('execution_log', []))}")
        
        if result.get('execution_log'):
            print("\nüìã Execution Log:")
            for i, log_entry in enumerate(result['execution_log'], 1):
                print(f"{i}. {log_entry['step_name']} - {log_entry['result'].get('message', 'No message')}")
        
        if result.get('final_output'):
            print(f"\nüéØ Final Output: {result['final_output']}")
    
    except Exception as e:
        print(f"‚ùå Error running multi-agent workflow: {str(e)}")
