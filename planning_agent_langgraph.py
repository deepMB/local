from typing import TypedDict, List, Optional, Any, Dict, Literal
from langgraph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import BaseTool
from langchain_openai import ChatOpenAI
from langchain.agents import create_react_agent, AgentExecutor
from langchain_core.prompts import PromptTemplate
import json
import re
from pydantic import BaseModel, Field

# Agent State Definition
class AgentState(TypedDict):
    """
    Defines the shared state for the playbook-driven multi-agent system.
    """
    error_code: int
    sop_content: str
    
    playbook: Optional[Dict[str, Any]]
    """The structured JSON workflow graph generated by the Planning Agent."""

    execution_queue: List[str]
    """A queue of node IDs from the playbook that the Execution Agent needs to process."""
    
    data: Optional[Any]
    """Holds operational data, like the pandas DataFrame for error 935."""

    last_tool_result: Optional[Dict[str, Any]]
    """Stores the output from the last executed tool for conditional evaluation."""

    final_output: Dict[str, Any]
    """A dictionary to accumulate final results and statuses from the workflow."""

    current_step_id: Optional[str]
    """Currently executing step ID."""

    execution_status: str
    """Status of execution: 'planning', 'executing', 'completed', 'failed'."""

    execution_log: List[Dict[str, Any]]
    """Log of all executed steps and their results."""


# Playbook Schema for structured output
class PlaybookStep(BaseModel):
    """Represents a single step in the playbook"""
    id: str = Field(description="Unique identifier for the step")
    name: str = Field(description="Human-readable name of the step")
    action: str = Field(description="The action to be performed")
    tool_name: Optional[str] = Field(description="Name of the tool to use, if applicable")
    tool_args: Optional[Dict[str, Any]] = Field(description="Arguments for the tool")
    condition: Optional[str] = Field(description="Condition to evaluate for branching")
    next_steps: Dict[str, str] = Field(description="Next steps based on conditions (success, failure, etc.)")
    description: str = Field(description="Detailed description of what this step does")


class PlanningAgent:
    """
    Planning Agent that reads SOPs and creates structured JSON playbooks.
    """
    
    def __init__(self, llm: ChatOpenAI, available_tools: List[BaseTool]):
        self.llm = llm
        self.available_tools = available_tools
        self.tool_names = [tool.name for tool in available_tools]
        
    def analyze_sop(self, state: AgentState) -> AgentState:
        """
        Analyzes the SOP content and creates a structured playbook.
        """
        print("🔍 Planning Agent: Starting SOP analysis...")
        
        sop_content = state["sop_content"]
        error_code = state["error_code"]
        
        # Update execution status
        state["execution_status"] = "planning"
        
        # Create the system prompt for SOP analysis
        system_prompt = f"""
        You are an expert SOP (Standard Operating Procedure) analyzer and workflow designer.
        
        Your task is to analyze the given SOP content and create a structured JSON playbook that can be executed by an automation agent.
        
        Available tools that can be used in the playbook: {', '.join(self.tool_names)}
        
        Guidelines for creating the playbook:
        1. Break down the SOP into discrete, actionable steps
        2. Identify decision points and conditional logic (IF/ELSE scenarios)
        3. Map each step to appropriate tools where applicable
        4. Create a flow that handles both success and failure paths
        5. Ensure each step has clear next steps based on outcomes
        6. Use meaningful IDs for steps (e.g., "step_001_validate_data", "step_002_check_connection")
        
        For conditional steps:
        - Use "condition" field to specify what to evaluate
        - Use "next_steps" to define paths: {{"success": "next_step_id", "failure": "error_step_id", "default": "default_step_id"}}
        
        The playbook should be comprehensive enough that an execution agent can follow it step-by-step without ambiguity.
        
        Error Code Context: {error_code}
        
        IMPORTANT: Return ONLY the JSON playbook, no other text or explanations.
        """
        
        human_prompt = f"""
        Create a detailed JSON playbook for this SOP:
        
        {sop_content}
        
        Required JSON structure:
        {{
            "name": "Playbook name",
            "description": "What this playbook does",
            "start_step": "first_step_id",
            "steps": {{
                "step_id": {{
                    "id": "step_id",
                    "name": "Step name",
                    "action": "execute_tool|evaluate_condition|notify|end",
                    "tool_name": "tool_name_if_applicable",
                    "tool_args": {{"arg": "value"}},
                    "condition": "condition_to_evaluate_if_applicable",
                    "next_steps": {{"success": "next_id", "failure": "error_id", "default": "default_id"}},
                    "description": "What this step does"
                }}
            }}
        }}
        """
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        try:
            # Get structured output from LLM
            response = self.llm.invoke(messages)
            
            # Parse the response to extract JSON
            playbook_json = self._extract_json_from_response(response.content)
            
            # Validate and structure the playbook
            playbook = self._validate_and_structure_playbook(playbook_json)
            
            # Update state with the created playbook
            state["playbook"] = playbook
            state["execution_queue"] = [playbook["start_step"]] if playbook else []
            state["execution_status"] = "ready_to_execute"
            
            print(f"✅ Planning Agent: Successfully created playbook with {len(playbook.get('steps', {}))} steps")
            print(f"📋 Start step: {playbook['start_step']}")
            
        except Exception as e:
            print(f"❌ Planning Agent Error: {str(e)}")
            state["playbook"] = None
            state["execution_queue"] = []
            state["execution_status"] = "failed"
            state["final_output"]["error"] = f"Planning failed: {str(e)}"
        
        return state
    
    def _extract_json_from_response(self, response_content: str) -> Dict[str, Any]:
        """Extracts JSON from the LLM response."""
        # Try to find JSON block in the response
        json_pattern = r'```json\s*(.*?)\s*```'
        json_match = re.search(json_pattern, response_content, re.DOTALL)
        
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON without code blocks
            json_str = response_content.strip()
        
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            # Fallback: try to extract JSON from anywhere in the text
            json_start = response_content.find('{')
            json_end = response_content.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = response_content[json_start:json_end]
                return json.loads(json_str)
            else:
                raise ValueError(f"Could not extract valid JSON from response: {str(e)}")
    
    def _validate_and_structure_playbook(self, playbook_json: Dict[str, Any]) -> Dict[str, Any]:
        """Validates the playbook structure."""
        if "steps" not in playbook_json:
            raise ValueError("Playbook must contain 'steps' field")
        
        if "start_step" not in playbook_json:
            playbook_json["start_step"] = list(playbook_json["steps"].keys())[0]
        
        # Validate that start_step exists in steps
        if playbook_json["start_step"] not in playbook_json["steps"]:
            raise ValueError(f"Start step '{playbook_json['start_step']}' not found in steps")
        
        # Ensure each step has required fields
        for step_id, step_data in playbook_json["steps"].items():
            if "id" not in step_data:
                step_data["id"] = step_id
            if "next_steps" not in step_data:
                step_data["next_steps"] = {"default": "END"}
            if "action" not in step_data:
                step_data["action"] = "execute_tool"
        
        return playbook_json


class ExecutionAgent:
    """
    Execution Agent that executes the playbook using ReAct pattern.
    """
    
    def __init__(self, llm: ChatOpenAI, available_tools: List[BaseTool]):
        self.llm = llm
        self.available_tools = available_tools
        self.tool_dict = {tool.name: tool for tool in available_tools}
        
        # Create ReAct agent
        self.react_prompt = PromptTemplate.from_template("""
        You are an execution agent following a structured playbook. 
        
        Current step to execute: {current_step}
        Step details: {step_details}
        Available tools: {tool_names}
        Previous results: {context}
        
        Execute the current step exactly as specified. If you need to use a tool:
        1. Call the appropriate tool with the specified arguments
        2. Evaluate the result
        3. Determine the next step based on the outcome
        
        If the tool result is unsatisfactory or no suitable tool is available, indicate failure.
        
        Use the tools to complete the task, then provide your final answer including:
        - What you executed
        - The result
        - The next step to take (success/failure/default path)
        
        {agent_scratchpad}
        """)
        
    def execute_step(self, state: AgentState) -> AgentState:
        """
        Executes the current step in the playbook.
        """
        if not state["execution_queue"]:
            state["execution_status"] = "completed"
            return state
            
        current_step_id = state["execution_queue"][0]
        state["current_step_id"] = current_step_id
        
        print(f"🔧 Execution Agent: Executing step '{current_step_id}'")
        
        # Get current step details
        if not state["playbook"] or current_step_id not in state["playbook"]["steps"]:
            state["execution_status"] = "failed"
            state["final_output"]["error"] = f"Step '{current_step_id}' not found in playbook"
            return state
            
        current_step = state["playbook"]["steps"][current_step_id]
        
        # Handle END step
        if current_step_id == "END":
            state["execution_status"] = "completed"
            state["execution_queue"] = []
            print("✅ Execution Agent: Workflow completed successfully")
            return state
        
        try:
            # Execute the step based on its action type
            if current_step["action"] == "execute_tool":
                result = self._execute_tool_step(current_step, state)
            elif current_step["action"] == "evaluate_condition":
                result = self._evaluate_condition_step(current_step, state)
            elif current_step["action"] == "notify":
                result = self._notify_step(current_step, state)
            else:
                result = {"status": "success", "message": f"Executed step: {current_step['name']}"}
            
            # Log the execution
            log_entry = {
                "step_id": current_step_id,
                "step_name": current_step.get("name", ""),
                "result": result,
                "timestamp": "now"  # In real implementation, use actual timestamp
            }
            
            if "execution_log" not in state:
                state["execution_log"] = []
            state["execution_log"].append(log_entry)
            
            # Store last tool result
            state["last_tool_result"] = result
            
            # Determine next step
            next_step_id = self._determine_next_step(current_step, result)
            
            # Update execution queue
            state["execution_queue"] = state["execution_queue"][1:]  # Remove current step
            
            if next_step_id and next_step_id != "END":
                state["execution_queue"].insert(0, next_step_id)  # Add next step to front
            
            print(f"✅ Step '{current_step_id}' completed. Next: '{next_step_id}'")
            
        except Exception as e:
            print(f"❌ Execution Agent Error in step '{current_step_id}': {str(e)}")
            state["execution_status"] = "failed"
            state["final_output"]["error"] = f"Execution failed at step '{current_step_id}': {str(e)}"
            
        return state
    
    def _execute_tool_step(self, step: Dict[str, Any], state: AgentState) -> Dict[str, Any]:
        """Execute a tool-based step."""
        tool_name = step.get("tool_name")
        tool_args = step.get("tool_args", {})
        
        if not tool_name or tool_name not in self.tool_dict:
            return {"status": "failure", "message": f"Tool '{tool_name}' not available"}
        
        try:
            tool = self.tool_dict[tool_name]
            result = tool.invoke(tool_args)
            
            return {
                "status": "success",
                "tool_name": tool_name,
                "tool_args": tool_args,
                "tool_result": result,
                "message": f"Successfully executed {tool_name}"
            }
        except Exception as e:
            return {
                "status": "failure",
                "tool_name": tool_name,
                "error": str(e),
                "message": f"Failed to execute {tool_name}: {str(e)}"
            }
    
    def _evaluate_condition_step(self, step: Dict[str, Any], state: AgentState) -> Dict[str, Any]:
        """Evaluate a conditional step."""
        condition = step.get("condition", "")
        last_result = state.get("last_tool_result", {})
        
        # Simple condition evaluation (can be enhanced with more complex logic)
        if "success" in condition.lower():
            condition_met = last_result.get("status") == "success"
        elif "failure" in condition.lower():
            condition_met = last_result.get("status") == "failure"
        else:
            # Default condition evaluation
            condition_met = bool(last_result.get("status") == "success")
        
        return {
            "status": "success" if condition_met else "failure",
            "condition": condition,
            "condition_met": condition_met,
            "message": f"Condition '{condition}' evaluated to {condition_met}"
        }
    
    def _notify_step(self, step: Dict[str, Any], state: AgentState) -> Dict[str, Any]:
        """Handle notification steps."""
        message = step.get("description", "Notification step executed")
        
        # In real implementation, this could send actual notifications
        print(f"📢 Notification: {message}")
        
        return {
            "status": "success",
            "message": f"Notification sent: {message}"
        }
    
    def _determine_next_step(self, current_step: Dict[str, Any], result: Dict[str, Any]) -> str:
        """Determine the next step based on the current step result."""
        next_steps = current_step.get("next_steps", {})
        result_status = result.get("status", "unknown")
        
        # Try to find next step based on result status
        if result_status in next_steps:
            return next_steps[result_status]
        elif "default" in next_steps:
            return next_steps["default"]
        else:
            return "END"


def create_multi_agent_workflow(llm: ChatOpenAI, available_tools: List[BaseTool]) -> StateGraph:
    """
    Creates the multi-agent workflow with both Planning and Execution agents.
    """
    planning_agent = PlanningAgent(llm, available_tools)
    execution_agent = ExecutionAgent(llm, available_tools)
    
    # Create the state graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("planning", planning_agent.analyze_sop)
    workflow.add_node("execution", execution_agent.execute_step)
    
    # Set entry point
    workflow.set_entry_point("planning")
    
    # Define routing logic
    def route_after_planning(state: AgentState) -> Literal["execution", "__end__"]:
        """Route after planning phase."""
        if state["execution_status"] == "ready_to_execute" and state["execution_queue"]:
            return "execution"
        else:
            return "__end__"
    
    def route_after_execution(state: AgentState) -> Literal["execution", "__end__"]:
        """Route after execution phase."""
        if state["execution_status"] == "completed" or state["execution_status"] == "failed":
            return "__end__"
        elif state["execution_queue"]:
            return "execution"
        else:
            return "__end__"
    
    # Add conditional edges
    workflow.add_conditional_edges(
        "planning",
        route_after_planning,
        {
            "execution": "execution",
            "__end__": END
        }
    )
    
    workflow.add_conditional_edges(
        "execution",
        route_after_execution,
        {
            "execution": "execution",
            "__end__": END
        }
    )
    
    return workflow


# Example usage and testing
if __name__ == "__main__":
    from langchain_core.tools import tool
    
    # Mock tools for demonstration
    @tool
    def validate_data(data_source: str) -> str:
        """Validates data from the specified source."""
        return f"Data validation completed for {data_source} - Status: Valid"
    
    @tool
    def check_database_connection(database_name: str) -> str:
        """Checks connection to the specified database."""
        return f"Database connection verified for {database_name} - Status: Connected"
    
    @tool
    def execute_query(query: str) -> str:
        """Executes a database query."""
        return f"Query executed successfully: {query} - Rows affected: 150"
    
    @tool
    def send_notification(message: str, recipient: str) -> str:
        """Sends a notification message."""
        return f"Notification sent to {recipient}: {message} - Status: Delivered"
    
    # Initialize LLM (replace with your preferred LLM)
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    # Available tools
    tools = [validate_data, check_database_connection, execute_query, send_notification]
    
    # Create the multi-agent workflow
    workflow = create_multi_agent_workflow(llm, tools)
    
    # Compile the graph
    app = workflow.compile()
    
    # Example SOP content
    sample_sop = """
    SOP for Error Code 935 - Data Validation Failure
    
    1. First, validate the incoming data source 'customer_data'
    2. If validation fails, check database connection to 'main_db'
    3. If connection is successful, execute repair query 'UPDATE customers SET status = active WHERE status IS NULL'
    4. If repair is successful, re-validate the data source
    5. If re-validation passes, send success notification to 'admin@company.com'
    6. If any step fails, send error notification with details to 'admin@company.com'
    """
    
    # Test the multi-agent system
    initial_state: AgentState = {
        "error_code": 935,
        "sop_content": sample_sop,
        "playbook": None,
        "execution_queue": [],
        "data": None,
        "last_tool_result": None,
        "final_output": {},
        "current_step_id": None,
        "execution_status": "planning",
        "execution_log": []
    }
    
    # Run the multi-agent workflow
    try:
        print("🚀 Starting Multi-Agent Workflow...")
        print("=" * 50)
        
        result = app.invoke(initial_state)
        
        print("=" * 50)
        print("📊 Final Results:")
        print(f"Execution Status: {result['execution_status']}")
        print(f"Steps Executed: {len(result.get('execution_log', []))}")
        
        if result.get('execution_log'):
            print("\n📋 Execution Log:")
            for i, log_entry in enumerate(result['execution_log'], 1):
                print(f"{i}. {log_entry['step_name']} - {log_entry['result'].get('message', 'No message')}")
        
        if result.get('final_output'):
            print(f"\n🎯 Final Output: {result['final_output']}")
    
    except Exception as e:
        print(f"❌ Error running multi-agent workflow: {str(e)}")
